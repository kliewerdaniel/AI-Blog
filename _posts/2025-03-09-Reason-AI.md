---
layout: post
title:  ReasonAI
date:   2025-03-09 10:42:44 -0500
---

**Building Intelligent AI Agents with Local Privacy: A Deep Dive into the Ollama Reasoning Agent Framework**  
*(A Developer's Guide to Core Concepts & Practical Implementation)*  

---

### **Why This Framework Matters**  
In an era of cloud-dependent AI services, running sophisticated reasoning agents locally is revolutionary. The reasonai03 framework combines Next.js' full-stack capabilities with Ollama's local AI processing to create a new paradigm: **private, transparent AI task execution**. This guide will teach you not just how to use the framework, but the architectural patterns that make it powerful.

---

## **Core Concepts to Master**  

### 1. **Task Decomposition Architecture**  
**What It Solves:** Breaking complex goals ("Plan a European vacation") into executable steps.  

**Implementation Insight:**  
The framework uses a recursive prompt-chaining pattern:  
```python  
# Pseudo-code of the decomposition process
def decompose_task(goal):
    prompt = f"""
    Break this into maximally parallelizable steps:
    GOAL: {goal}
    
    Respond in JSON format:
    {{
        "steps": [
            {{
                "id": "step_1",
                "description": "...",
                "depends_on": []
            }}
        ]
    }}
    """
    return ollama.generate(prompt)
```  
**Key Learnings:**  
- Dependency mapping for parallel vs sequential execution  
- Error recovery through step retries  
- Context preservation between steps

---

### 2. **Real-Time Reasoning Streams**  
**What It Solves:** Black-box AI operations without progress visibility.  

**Next.js Implementation:**  
The framework uses Server-Sent Events (SSE) for streaming:  
```typescript
// app/api/agent/route.ts
export async function POST(req: Request) {
  const encoder = new TextEncoder();
  
  const stream = new ReadableStream({
    async start(controller) {
      const callback = (token: string) => {
        controller.enqueue(encoder.encode(token));
      };
      
      await runAgent(params, callback);
      controller.close();
    },
  });

  return new Response(stream);
}
```  
**UI Pattern:**  
```tsx
// app/components/StreamDisplay.tsx
useEffect(() => {
  const eventSource = new EventSource('/api/agent');
  
  eventSource.onmessage = (e) => {
    setOutput(prev => prev + e.data);
  };

  return () => eventSource.close();
}, []);
```

---

### 3. **Local-First AI with Ollama**  
**Privacy Architecture:**  

*Data never leaves your machine through:*
1. No external API calls
2. All processing in Node.js worker threads
3. Optional disk encryption layer

**Model Management Tips:**  
```bash
# Use different models per task type
ollama pull llama2:13b # For complex reasoning
ollama pull mistral # For fast operations
```

---

## **Advanced Implementation Guide**

### **Customizing the Reasoning Engine**  
Modify the agent's decision-making process:  

1. **Edit the Reasoning Prompts**  
```typescript
// lib/prompts.ts
export const DECOMPOSE_PROMPT = `
You're a expert project manager. Follow these rules:

1. Always identify resource needs first
2. Check for legal constraints
3. Maximum 3 parallel tasks

Goal: {userGoal}
`;
```

2. **Add Custom Processing Hooks**  
```typescript
// lib/agent/hooks.ts
export const useValidation = (step: Step) => {
  if (step.type === 'web_search') {
    return validateSources(step.content);
  }
};
```

---

### **Performance Optimization**  
1. **Parallel Step Execution**  
```ts
// lib/execution.ts
const parallelSteps = steps.filter(s => s.depends_on.length === 0);
await Promise.all(parallelSteps.map(executeStep));
```

2. **Local Cache Layer**  
```ts
// lib/cache.ts
const cachedResult = await localforage.getItem(stepHash);
if (cachedResult) return cachedResult;
```

---

## **Use Case Example: Vacation Planner**  
**User Input:**  
"Plan a 2-week Japan trip with budget $5k"

**Agent Execution Flow:**  
1. Decompose into:  
   - Flight research  
   - Visa requirements  
   - Hotel booking  
   - Itinerary creation  

2. Parallel execution of flights/visa/hotels  

3. Stream updates:  
   âœ“ Found 3 flight options under $1.5k  
   â†’ Visa requires 6-week processing!  

4. Adaptive re-planning:  
   "Adjusting itinerary for shorter stay"

---

## **Extending the Framework**  

### **1. Add New Capabilities**  
**Example: PDF Analysis Module**  
```ts
// app/api/analyze-pdf/route.ts
export async function POST(req: Request) {
  const pdfText = await extractText(req.body);
  const analysis = await ollama.generate(`
    Analyze this PDF:
    ${pdfText}
    
    Output JSON with:
    - Key dates
    - Financial figures
    - Risks identified
  `);
  
  return Response.json(analysis);
}
```

### **2. Implement User Authentication**  
```ts
// middleware.ts
export async function middleware(req: NextRequest) {
  if (req.nextUrl.pathname.startsWith('/agent')) {
    const session = await getSession();
    if (!session) return new Response('Unauthorized', {status: 401});
  }
}
```

---

## **Best Practices**  

1. **Model Selection Guide**  
| Task Type          | Recommended Model | RAM Needs |
|---------------------|-------------------|-----------|
| Complex Reasoning   | llama2:70b        | 32GB+     |
| Fast Operations     | mistral           | 16GB      |
| Code Generation     | codellama         | 24GB      |

2. **Error Handling Patterns**  
```ts
// lib/errorHandling.ts
export const handleStepError = (error: Error) => {
  if (error.message.includes('context length')) {
    return { action: 'split', retries: 3 };
  }
  
  return { action: 'abort', message: error.message };
};
```

---

## **Troubleshooting**  

**Common Issues:**  
- **"Ollama not responding"**:  
  ```bash
  # Check Ollama service
  curl http://localhost:11434
  ```
  
- **"Model not found"**:  
  ```bash
  ollama pull mistral
  ```

- **Stream freezing**:  
  Implement heartbeat mechanism:  
  ```ts
  setInterval(() => send('ping'), 15000);
  ```

---

## **Conclusion & Next Steps**  

The reasonai03 framework demonstrates that **local AI agents can rival cloud services** when properly architected. Key takeaways:  

1. **Patterns to Reuse:**  
   - SSE for real-time updates  
   - Recursive task decomposition  
   - Local model management  

2. **Future Extensions:**  
   - Add vision capabilities with LLaVA  
   - Implement RAG for document grounding  
   - Create distributed Ollama clusters  

**Start Experimenting:**  
```bash
git clone https://github.com/kliewerdaniel/reasonai03.git
npm install && npm run dev
```



**Contributions Welcome!**  
We're actively maintaining this project - submit PRs for:  
- New model integrations  
- Additional UI components  
- Performance improvements  

Let's build the future of private AI together! ðŸš€